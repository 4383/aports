From 36e8b6a28be5d4ffad966386b1e1c0d0dc6ca11a Mon Sep 17 00:00:00 2001
From: Rich Felker <dalias@aerifal.cx>
Date: Mon, 2 Nov 2015 16:16:00 -0500
Subject: [PATCH] use explicit __cp_cancel label in cancellable syscall asm for
 all archs

previously, only archs that needed to do stack cleanup defined a
__cp_cancel label for acting on cancellation in their syscall asm, and
a default definition was provided by a weak alias to __cancel, the C
function. this resulted in wrong codegen for arm on gcc versions
affected by pr 68178 and possibly similar issues (like pr 66609) on
other archs, and also created an inconsistency where the __cp_begin
and __cp_end labels were treated as const data but __cp_cancel was
treated as a function. this in turn caused incorrect code generation
on archs where function pointers point to function descriptors rather
than code (for now, only sh/fdpic).
---
 src/thread/aarch64/syscall_cp.s    |  7 +++----
 src/thread/microblaze/syscall_cp.s |  4 +++-
 src/thread/or1k/syscall_cp.s       |  5 ++++-
 src/thread/powerpc/syscall_cp.s    |  4 +++-
 src/thread/pthread_cancel.c        | 10 ++--------
 src/thread/sh/syscall_cp.s         | 22 +++++++++++-----------
 src/thread/x32/syscall_cp.s        |  4 +++-
 src/thread/x86_64/syscall_cp.s     |  4 +++-
 8 files changed, 32 insertions(+), 28 deletions(-)

diff --git a/src/thread/aarch64/syscall_cp.s b/src/thread/aarch64/syscall_cp.s
index 30e677c..41db68a 100644
--- a/src/thread/aarch64/syscall_cp.s
+++ b/src/thread/aarch64/syscall_cp.s
@@ -17,7 +17,7 @@
 __syscall_cp_asm:
 __cp_begin:
 	ldr w0,[x0]
-	cbnz w0,1f
+	cbnz w0,__cp_cancel
 	mov x8,x1
 	mov x0,x2
 	mov x1,x3
@@ -28,6 +28,5 @@ __cp_begin:
 	svc 0
 __cp_end:
 	ret
-
-	// cbnz might not be able to jump far enough
-1:	b __cancel
+__cp_cancel:
+	b __cancel
diff --git a/src/thread/microblaze/syscall_cp.s b/src/thread/microblaze/syscall_cp.s
index 51599c9..b0df61c 100644
--- a/src/thread/microblaze/syscall_cp.s
+++ b/src/thread/microblaze/syscall_cp.s
@@ -11,7 +11,7 @@
 __syscall_cp_asm:
 __cp_begin:
 	lwi     r5, r5, 0
-	bnei    r5, __cancel
+	bnei    r5, __cp_cancel
 	addi    r12, r6, 0
 	add     r5, r7, r0
 	add     r6, r8, r0
@@ -23,3 +23,5 @@ __cp_begin:
 __cp_end:
 	rtsd    r15, 8
 	nop
+__cp_cancel:
+	bri     __cancel
diff --git a/src/thread/or1k/syscall_cp.s b/src/thread/or1k/syscall_cp.s
index 2c0bf0e..7951166 100644
--- a/src/thread/or1k/syscall_cp.s
+++ b/src/thread/or1k/syscall_cp.s
@@ -12,7 +12,7 @@ __syscall_cp_asm:
 __cp_begin:
 	l.lwz	r3, 0(r3)
 	l.sfeqi	r3, 0
-	l.bnf	__cancel
+	l.bnf	__cp_cancel
 	 l.ori	r11, r4, 0
 	l.ori	r3, r5, 0
 	l.ori	r4, r6, 0
@@ -24,3 +24,6 @@ __cp_begin:
 __cp_end:
 	l.jr	r9
 	 l.nop
+__cp_cancel:
+	l.j	__cancel
+	 l.nop
diff --git a/src/thread/powerpc/syscall_cp.s b/src/thread/powerpc/syscall_cp.s
index 20b5e0a..77f8938 100644
--- a/src/thread/powerpc/syscall_cp.s
+++ b/src/thread/powerpc/syscall_cp.s
@@ -38,7 +38,7 @@ __cp_begin:
 	cmpwi cr7, 0, 0 #compare r0 with 0, store result in cr7. 
 	beq+ cr7, 1f #jump to label 1 if r0 was 0
 	
-	b __cancel #else call cancel 
+	b __cp_cancel #else call cancel
 1:
 	#ok, the cancel flag was not set
 	# syscall: number goes to r0, the rest 3-8
@@ -55,3 +55,5 @@ __cp_end:
 	#else negate result.
 	neg 3, 3
 	blr
+__cp_cancel:
+	b __cancel
diff --git a/src/thread/pthread_cancel.c b/src/thread/pthread_cancel.c
index 6eaf72c..c4631f0 100644
--- a/src/thread/pthread_cancel.c
+++ b/src/thread/pthread_cancel.c
@@ -7,7 +7,7 @@
 #ifdef SHARED
 __attribute__((__visibility__("hidden")))
 #endif
-long __cancel(), __cp_cancel(), __syscall_cp_asm(), __syscall_cp_c();
+long __cancel(), __syscall_cp_asm(), __syscall_cp_c();
 
 long __cancel()
 {
@@ -18,12 +18,6 @@ long __cancel()
 	return -ECANCELED;
 }
 
-/* If __syscall_cp_asm has adjusted the stack pointer, it must provide a
- * definition of __cp_cancel to undo those adjustments and call __cancel.
- * Otherwise, __cancel provides a definition for __cp_cancel. */
-
-weak_alias(__cancel, __cp_cancel);
-
 long __syscall_cp_asm(volatile void *, syscall_arg_t,
                       syscall_arg_t, syscall_arg_t, syscall_arg_t,
                       syscall_arg_t, syscall_arg_t, syscall_arg_t);
@@ -56,7 +50,7 @@ static void _sigaddset(sigset_t *set, int sig)
 #ifdef SHARED
 __attribute__((__visibility__("hidden")))
 #endif
-extern const char __cp_begin[1], __cp_end[1];
+extern const char __cp_begin[1], __cp_end[1], __cp_cancel[1];
 
 static void cancel_handler(int sig, siginfo_t *si, void *ctx)
 {
diff --git a/src/thread/sh/syscall_cp.s b/src/thread/sh/syscall_cp.s
index c3cafac..bb848ef 100644
--- a/src/thread/sh/syscall_cp.s
+++ b/src/thread/sh/syscall_cp.s
@@ -14,17 +14,8 @@ __syscall_cp_asm:
 __cp_begin:
 	mov.l @r4, r4
 	tst   r4, r4
-	bt    2f
-
-	mov.l L1, r0
-	braf  r0
-	 nop
-1:
-
-.align 2
-L1:	.long __cancel@PLT-(1b-.)
-
-2:	mov   r5, r3
+	bf    __cp_cancel
+	mov   r5, r3
 	mov   r6, r4
 	mov   r7, r5
 	mov.l @r15, r6
@@ -43,3 +34,12 @@ __cp_end:
 
 	rts
 	 nop
+
+__cp_cancel:
+	mov.l 2f, r0
+	braf  r0
+	 nop
+1:
+
+.align 2
+2:	.long __cancel@PCREL-(1b-.)
diff --git a/src/thread/x32/syscall_cp.s b/src/thread/x32/syscall_cp.s
index 79709a5..9805af0 100644
--- a/src/thread/x32/syscall_cp.s
+++ b/src/thread/x32/syscall_cp.s
@@ -14,7 +14,7 @@ __syscall_cp_internal:
 __cp_begin:
 	mov (%rdi),%eax
 	test %eax,%eax
-	jnz __cancel
+	jnz __cp_cancel
 	mov %rdi,%r11
 	mov %rsi,%rax
 	mov %rdx,%rdi
@@ -27,3 +27,5 @@ __cp_begin:
 	syscall
 __cp_end:
 	ret
+__cp_cancel:
+	jmp __cancel
diff --git a/src/thread/x86_64/syscall_cp.s b/src/thread/x86_64/syscall_cp.s
index 1a0fd5d..4f10171 100644
--- a/src/thread/x86_64/syscall_cp.s
+++ b/src/thread/x86_64/syscall_cp.s
@@ -14,7 +14,7 @@ __syscall_cp_asm:
 __cp_begin:
 	mov (%rdi),%eax
 	test %eax,%eax
-	jnz __cancel
+	jnz __cp_cancel
 	mov %rdi,%r11
 	mov %rsi,%rax
 	mov %rdx,%rdi
@@ -27,3 +27,5 @@ __cp_begin:
 	syscall
 __cp_end:
 	ret
+__cp_cancel:
+	jmp __cancel
-- 
2.7.0

